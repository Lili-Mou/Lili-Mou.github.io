<html><head><meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"></head><body>
<p>
<h1>Lili Mou, PhD</h1>
<h3><a href="calendar.html" target="_blank">Calendar</a></h3>
<p>
<b>Email:</b><br/>
	LMOU [dot] ualberta [at] ca<br/>
  doublepower [dot] mou [at] gmail [dot] com<br/>

<b>Note:</b> Please send to <b>at most</b> one email address of mine.
</p>


<table border="0" width="600px">                                              

<tr><td>
<br/>

Dr. Lili Mou is an Assistant Professor at the Department of Computing Science, University of Alberta. Lili received his BS and PhD degrees in 2012 and 2017, respectively, from School of EECS, Peking University. After that, he worked as a postdoctoral fellow at the University of Waterloo and a research scientist at Adeptmind (a startup in Toronto, Canada). His research interests include deep learning applied to natural language processing as well as programming language processing. He has publications at top conferences and journals, including AAAI, ACL, CIKM, COLING, EMNLP, ICASSP, ICLR, ICML, IJCAI, INTERSPEECH, NAACL-HLT, and TACL (in alphabetic order). He also has tutorials at EMNLP-IJCNLP'19 and ACL'20. [<a href="LiliMou.pdf" target="_blank">CV</a>]
</td></tr></table>

<br/>
	
	<h2>Admitting</h2>
	I am admitting all-level students, postdocs, as well as visiting scholars. <br/>
	
	Master's and PhD application should be addressed to the University <a href="https://www.ualberta.ca/computing-science/graduate-studies/programs-and-admissions" target="_blank">portal</a>.<br/> <br/>
	
	Requirements for all students:

	<ul>
		<li>Coding ability (implementing algorithms as well as using existing toolkits)</li>
		<li>Math background (being able to go through equations and proofs of common machine learning models)</li>
		<li>Passion for scientific research (motivation, curiosity, persistence, etc.)</li>
	</ul>

	<a href="admitting.html" target="_blank">See here for detailed requirements</a>.



<h2>Teaching</h2>

<b>CMPUT 651:</b> Deep Learning for NLP [<a href="teaching/651_2019/651_2019.html" target="_blank">Fall 2019</a>]<br/></br>
<b>CMPUT 466/566:</b> Introduction to Machine Learning [<a href="teaching/466_566_2020/466_566_2020.html" target="_blank">Winter 2020</a>]<br/></br>
<b>Independent Study</b>:<br/> 
I feel happy to offer the Independent Study course for both undergraduate and graduate students.<br/> 
A student interested in such a research course should write me a letter of motivation.<br/> 
	The project idea could come from either the student or the instructor, and ideally both.
<br/></br>
<h2>Seminars</h2>
In our seminars, we discuss machine learning theories, algorithms,<br/>
and applications (with special interest in NLP). We start from the foundations,<br/> and move to the frontiers.<br/>
<br/>
<a href="seminar.html" target="_blank">Please visit here for contents.</a>
<br/><br/>
<p></p>

<h2>Publications</h2>


<b>Copyright announcement:</b> Copyrights of published papers might be held by publishers. All rights are reserved for other materials, including drafts, slides, and source code. Whenever not conflicting with copyright laws, I permit free use for non-commerical purposes. Please cite my papers if you use them for research. In particular, if a paper is accompanied with source code, the URL is available in the paper. Please notice, however, there's no
guarantee that my code is executable in your environment.<br>

<br/>

Useful links: <a href="publication.html" target="_blank">Complete list</a>,
<a href="https://scholar.google.com/citations?user=32UrMrQAAAAJ&hl=en" target="_blank">Google Scholar</a>,
<a href="http://dblp.uni-trier.de/pers/hd/m/Mou:Lili" target="_blank">DBLP</a>
<br /><br />

<h3>Book</h3>
<table border="0" width="850px">
<tr><td>
<ul>
<li><b>Lili Mou</b>, Zhi Jin. <i>Tree-Based Convolutional Neural Networks: Principles and Applications</i>, Springer, 2018. [<a href="https://www.springer.com/us/book/9789811318696" target="_blank">url</a>]</li>
</ul>
</td>
</tr>
</table>

<h3>New</h3>
<table border="0" width="850px">
<tr><td>
<ul>
	
	<li>Nabiha Asghar,<sup>1</sup> <b>Lili Mou</b>,<sup>1</sup> Kira A Selby, Kevin D Pantasdo, Pascal Poupart, Xin Jiang. Progressive memory banks for incremental domain adaptation. 
		In <i>Proc. ICLR</i>, 2020. [<a target="_blank" href="https://arxiv.org/pdf/1811.00239.pdf">pdf</a>]
	</li>
<br/>
	
	<li>Zeyu Sun, Qihao Zhu, Yingfei Xiong, Yican Sun, <b>Lili Mou</b>, Lu Zhang. TreeGen: A tree-based Transformer architecture for code generation. In <i>Proc. AAAI</i>, 2020. 
		[<a href="https://arxiv.org/abs/1911.09983" target="_blank">pdf</a>]
		</li><br/>
		
	<li>Xianggen Liu, <b>Lili Mou</b>, Haotian Cui, Zhengdong Lu, Sen Song. Finding decision jumps in text classification. <i>Neurocomputing</i>, vol 371, pages 177--187, 2020. [<a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S0925231219312263">url</a>] </li>
</ul>

	

<br/>

<h3>Selected Refereed Papers</h3>
[Selection is NOT based on the venue or length of a paper.]
<ul>
	
	<li> Bowen Li, <b>Lili Mou</b>, Frank Keller. An imitation learning approach to unsupervised parsing. In <i>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL-short)</i>, pages 3485--3492, 2019. [<a target="_blank" href="https://www.aclweb.org/anthology/P19-1338.pdf">pdf</a>, <a href="resource/UP.pdf"  target="_blank" >slides</a> (courtesy of BL)] <font color="red">(Best paper nomination)</font>
	</li><br/>
		
		
		
		
		<li>Hareesh Bahuleyan, <b>Lili Mou</b>, Hao Zhou, Olga Vechtomova. Stochastic Wasserstein autoencoder for probabilistic sentence generation. In <i>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT short)</i>, pages 4068--4076, 2019. [<a target="_blank" href="https://www.aclweb.org/anthology/N19-1411.pdf">pdf</a>, <a target="_blank" href="resource/wae.pdf">slides</a>]</li><br />
			
			<li>Ning Miao, Hao Zhou, <b>Lili Mou</b>, Rui Yan, Lei Li. CGMH: Constrained sentence generation by Metropolis-Hastings sampling. In <i>Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI)</i>, pages 6834--6942, 2019. [<a href="paper/2019-AAAI-MH.pdf" target="_blank">pdf</a>]</li><br />
				
				
				
				
<li>Hareesh Bahuleyan,<SUP>1</SUP> <b>Lili Mou</b>,<SUP>1</SUP> Olga Vechtomova, Pascal Poupart. Variational attention for sequence-to-sequence models. In <i>Proceedings of the International Conference on Computational Linguistics (COLING)</i>, pages 1672--1682, 2018. Also presented at <i>TADGM Workshop @ICML</i>, 2018. [<a href="http://aclweb.org/anthology/C18-1142.pdf" target="_blank">pdf</a>, <a href="resource/vattn.pdf" target="_blank">slides</a>]</li><br />


<li><b>Lili Mou</b>, Zhengdong Lu, Hang Li, Zhi Jin. Coupling distributed and symbolic execution for natural language queries. In <i>Proceedings of the 34th International Conference on Machine Learning (ICML)</i>, pages 2518--2526, 2017. Also presented in <i>ICLR Workshop</i>, 2017. [<a href="http://proceedings.mlr.press/v70/mou17a/mou17a.pdf" target="_blank">pdf</a>, <a href="resource/coupling-ICML.pdf" target="_blank">slides</a> (courtesy of <a href="http://deeplycurious.ai/" target="_blank">ZL</a>), <a href="resource/coupling.pdf" target="_blank">slides</a>]</li><br/>



<li><b>Lili Mou</b>, Zhao Meng, Rui Yan, Ge Li, Yan Xu, Lu Zhang, Zhi Jin. How transferable are neural networks in NLP applications? In <i>Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP)</i>, pages 478--489, 2016.
[<a href="https://www.aclweb.org/anthology/D16-1046.pdf" target="_blank">pdf</a>]</li><br/>


 
<li>Yunchuan Chen, <b>Lili Mou</b>, Yan Xu, Ge Li, Zhi Jin. Compressing neural language models by sparse word representations. In <i>Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</i>, pages 226--235, 2016. [<a href="http://aclweb.org/anthology/P16-1022.pdf" target="_blank">pdf</a>]</li>



<br/><li><b>Lili Mou</b>, Ge Li, Lu Zhang, Tao Wang, Zhi Jin. 
Convolutional neural networks over tree structures for programming language processing.
In <i>Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence (AAAI)</i>, pages 1287--1293, 2016.
[<a href="paper/2016-AAAI-DL4program.pdf" target="_blank">pdf</a>]</li>

<br/><li><b>Lili Mou</b>,<sup>1</sup> Hao Peng,<sup>1</sup> Ge Li, Yan Xu, Lu Zhang, Zhi Jin. Discriminative neural sentence modeling by tree-based convolution. In <i>Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)</i>, pages 2315--2325, 2015. [<a href="https://www.aclweb.org/anthology/D15-1279.pdf" target="_blank">pdf</a>,
<a href="resource/tbcnn_slide.pdf" target="_blank">slides</a>]</li>


<br/><li>Yan Xu, <b>Lili Mou</b>, Ge Li, Yunchuan Chen, Hao Peng, Zhi Jin. Classifying relations via long short term memory networks along shortest dependency paths. In <i>Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)</i>, pages 1785--1794, 2015. [<a href="https://www.aclweb.org/anthology/D15-1206.pdf" target="_blank">pdf</a>, <a href="resource/sdp_slides.pdf" target="_blank">slides</a> (courtesy of YX)]</li>


</ul>
</td></tr>
</table>
<br/>
<sup>1</sup>=equal contribution.
<br/><br/>

<h2>Academic Service</h2>
<h3>Primary reviewer</h3> NAACL'16 (best reviewers), COLING'16, ACL'17, AAAI'18, NAACL'18, ACL'18, COLING'18 (PC and Mentor), <br/>
ACL'19, IJCAI'19, NeurIPS'19, <i>Computer Speech & Language</i>, <i>TKDE</i><br />


<h3>Talk</h3>
Lili Mou, Hao Zhou, Lei Li. Discreteness in Neural Natural Language Processing. Tutorial at EMNLP-IJCNLP, 2019.
[<a href="resource/emnlp19-1.pdf" target="_blank">Part I</a>, <a href="resource/emnlp19-2.pdf" target="_blank">Part II</a>, <a href="resource/emnlp19-3.pdf" target="_blank">Part III</a>]
<br>

<br>


<h3>Guest Lectures</h3>
<p></p><table border="0">
	
	<tr><td colspan="3"><b>Guest Lecture</b> of the "Deep Learning Techniques and Applications" course (11 May 2017):</td></tr>
	<tr><td></td><td></td><td><i>Neural Networks in NLP: The Curse of Indifferentiability</i> [slides: <a href="resource/NNinNLP_I.pdf" target="_blank">I</a>, <a href="resource/NNinNLP_II.pdf" target="_blank">II</a>, <a href="resource/NNinNLP_III.pdf" target="_blank">III</a>]</td></tr>
	
	<tr><td colspan="3"><b>Mini-Project Tutorial</b> for Undergrad. Res. Opportunities Conf. @ U Waterloo (22 and 23 Sep 2017):</td></tr>
	<tr><td></td><td></td><td><i>Adversarial Training and Security in Machine Learning</i>
			[<a href="resource/adv_samples.pdf" target="_blank">slides</a>, <a href="https://www.dropbox.com/s/iafhbi87mtk67gk/Adversarial.zip?dl=0" target="_blank">code</a>]</td></tr>
	
	<tr><td colspan="3"><b>Guest Lecture</b> of the "Text Analytics" course (4 July 2019):</td></tr>
	<tr><td></td><td></td><td><i>Sampling and Stochastic Search for Text Generation</i> [<a href="slides/MCMC.pdf" target="_blank">pdf</a>]

</tbody></table>

<h3>Co-Supervised Students</h3>
<table>
<tr><td width="200pt"><img src="alumni/hao.jpg" width="150pt" height="200pt"/></td>
    <td width="200pt"><img src="alumni/rui.jpg" width="150pt" height="200pt"/></td>
    <td width="200pt"><img src="alumni/zhao.jpg" width="150pt" height="200pt"/></td>
    <td width="200pt"><img src="alumni/bolin.jpg" width="150pt" height="200pt"/></td>
</tr>
<tr><td width="200pt">2014.7--2015.6<br/>Hao Peng (undergraduate)<br/>with publication at<br/> EMNLP-15.</td>
    <td width="200pt">2015.7--2016.3<br />Rui Men (undergraduate)<br/>with publication at<br /> ACL-16.</td>
    <td width="200pt">2015.7--2017.6<br/>Zhao Meng (undergraduate)<br/>with publications at<br/> EMNLP-16, CIKM-17 & AAAI-18 (student poster).</td>
    <td width="200pt">2015.7--2018.2<br />Bolin Wei (undergraduate<br/> -> master's student) with <br/> publication at ICASSP-19.</td>
</tr>

<tr>
    <td width="200pt"><img src="alumni/yiping.jpg" width="150pt" height="200pt"/></td>
    <td width="200pt"><img src="alumni/hareesh.jpg" width="150pt" height="200pt"/></td>
<td width="200pt"><img src="alumni/nabiha.jpg" width="150pt" height="200pt"/></td>
<td width="200pt"><img src="alumni/vineet.jpg" width="150pt" height="200pt"/></td>
</tr>
<tr>
    <td width="200pt">2016.1--2017.1<br />Yiping Song (PhD student)<br/>with publication at<br/> INTERSPEECH-16.</td>
    <td width="200pt">2017.9--2018.8<br />Hareesh Bahuleyan (master's student) with publication <br/> at COLING-18 & NAACL-19.</td>
    <td width="200pt">2017.9--2018.11<br />Nabiha Asghar (PhD student)<br/>with publication at ICLR-20. </td>
    <td width="200pt">2017.9--2018.8<br />Vineet John (master's student)<br/>with publication <br/> at ACL-19</td>
</tr>

</table>

<br/>








<hr />
<h2>Entertainment</h2>
Lili Mou's major hobbies include practicing calligraphy, watching yueju,<br />
visiting traditional Chinese architectures, taking MOOCs, and many others.
<br />
<br />

<h3>Gallery</h3>

<ul>
<li><i>Solo Exhibition (Jun 2015)</i>. I have been practicing calligraphy since I was 5 years old, <br />
supervised by Mr. Lei He. After a broad range of attempt, I am currently<br />
specialized in <i>Kai</i> (regular), <i>Xing</i> (illegible), and <i>Cao</i> (very illegible) styles. <br />
In 2015, I held my own calligraphy exhibition (albeit small and unofficial). <br />
Following are some pictures taken in the exhibition.
<br />
<a href="gallery/1.JPG" target="_blank"><img src="gallery/s1.JPG" width="125pt"/></a>
 <a href="gallery/2.JPG" target="_blank"><img src="gallery/s2.JPG" width="125pt"/></a>
 <a href="gallery/3.JPG" target="_blank"><img src="gallery/s3.JPG" width="125pt"/></a>
 <a href="gallery/4.JPG" target="_blank"><img src="gallery/s4.JPG" width="125pt"/></a>

</li>
<br/><br/>
<li><i>Held by Student Association of Calligraphy, Peking University (30 May--1 Jun, 2016)</i>.
<br />
<a href="gallery/201605_1.JPG" target="_blank"><img src="gallery/201605_1s.JPG" height="225pt"/></a>&nbsp;&nbsp;
 <a href="gallery/201605_2.JPG" target="_blank"><img src="gallery/201605_2s.JPG" height="225pt"/></a>&nbsp;&nbsp;
 <a href="gallery/201605_3.JPG" target="_blank"><img src="gallery/201605_3s.JPG" height="225pt"/></a>

</ul>

</body></html>


