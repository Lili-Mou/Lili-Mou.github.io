
<h2>Publications</h2>

<br />

<b>Copyright announcement:</b> Copyrights of published papers might be held by publishers. All rights are reserved for other materials, including drafts, slides, and source code. Whenever not conflicting with copyright laws, I permit free use for non-commerical purposes. Please cite my papers if you use them for research. In particular, if a paper is accompanied with source code, the URL is available in the paper. Please notice, however, there's no
guarantee that my code is executable in your environment.<br>

<br/>

Useful links: <a href="https://scholar.google.com/citations?user=32UrMrQAAAAJ&hl=en" target="_blank">Google Scholar</a>,
<a href="http://dblp.uni-trier.de/pers/hd/m/Mou:Lili" target="_blank">DBLP</a>
<br /><br />


<h3>Book</h3>
<table border="0" width="700px">
<tr><td>
<ul><font size="2">
<li><b>Lili Mou</b>, Zhi Jin. <i>Tree-Based Convolutional Neural Networks: Principles and Applications</i>, Springer, 2018. [<a href="https://www.springer.com/us/book/9789811318696" target="_blank">url</a>]</li></font>
</ul>
</td>
</tr>
</table>

<h3>Papers</h3>

<table border="0" width="700px" >

<tr><td>
<ol reversed><font size="2">
<li>Xianggen Liu, <b>Lili Mou</b>, Haotian Cui, Zhengdong Lu, Sen Song. Finding decision jumps in text classification. <i>Neurocomputing</i>, vol 371, pages 177--187, 2020. [<a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S0925231219312263">url</a>] </li><br/>
	
	
	<li>Yunli Wang, Yu Wu, <b>Lili Mou</b>, Zhoujun Li, Wenhan Chao. Harnessing pre-trained neural networks with rules for formality style transfer. In <i>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</i>, pages 3571--3576, 2019. [<a target="_blank" href="paper/2019-EMNLP.pdf">pdf</a>] </li><br/>
		

<li> Bowen Li, <b>Lili Mou</b>, Frank Keller. An imitation learning approach to unsupervised parsing. In <i>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL-short)</i>, pages 3485--3492, 2019. [<a target="_blank" href="paper/2019-ACL-UP.pdf">pdf</a>, <a href="resource/UP.pdf"  target="_blank" >slides</a> (courtesy of BL)] <font color="red">(Best short paper nomination)</font>
</li><br/>
	
<li> Vineet John, <b>Lili Mou</b>, Hareesh Bahuleyan, Olga Vechtomova. Disentangled representation learning for non-parallel text style transfer. In <i>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL)</i>, pages 424--434, 2019. [<a href="paper/2019-ACL-disentangle_sentiment.pdf" target="_blank">pdf</a>]
</li>
<br/>
		
		
<li>Yu Bao, Hao Zhou, Shujian Huang, Lei Li, <b>Lili Mou</b>, Olga Vechtomova, Xin-Yu Dai, Jiajun Chen. Generating sentences from disentangled syntactic and semantic spaces. In <i>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL)</i>, pages  6008--6019, 2019. [<a href="paper/2019-ACL-disentangle_syntax.pdf" target="_blank">pdf</a>]
			
</li><br/>
			
			
<li>Hareesh Bahuleyan, <b>Lili Mou</b>, Hao Zhou, Olga Vechtomova. Stochastic Wasserstein autoencoder for probabilistic sentence generation. In <i>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT short)</i>, pages 4068--4076, 2019. [<a target="_blank" href="https://www.aclweb.org/anthology/N19-1411">pdf</a>, <a target="_blank" href="resource/wae.pdf">slides</a>]</li><br />
				
<li>Ning Miao, Hao Zhou, <b>Lili Mou</b>, Rui Yan, Lei Li. CGMH: Constrained sentence generation by Metropolis-Hastings sampling. In <i>Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI)</i>, pages 6834--6942, 2019. [<a href="paper/2019-AAAI-MH.pdf" target="_blank">pdf</a>]</li><br />

<li>Zeyu Sun, Qihao Zhu, <b>Lili Mou</b>, Yingfei Xiong, Ge Li, Lu Zhang. A grammar-based structural CNN decoder for code generation. In <i>Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI)</i>, pages 7055--7062, 2019. [<a href="paper/2019-AAAI-code_gen.pdf" target="_blank">pdf</a>]</li><br />
		


<li>Bolin Wei,<SUP>1</SUP> Shuai Lu,<SUP>1</SUP> <b>Lili Mou</b>, Hao Zhou, Pascal Poupart, Ge Li, Zhi Jin. Why do neural dialog systems generate short and meaningless replies? A comparison between dialog and translation. In <i>Proceedings of the 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>, pages 7290--7294, 2019. [<a href="paper/2019-ICASSP.pdf" target="_blank">pdf</a>]</li><br />


<li>Hareesh Bahuleyan,<SUP>1</SUP> <b>Lili Mou</b>,<SUP>1</SUP> Olga Vechtomova, Pascal Poupart. Variational attention for sequence-to-sequence models. In <i>Proceedings of the International Conference on Computational Linguistics (COLING)</i>, pages 1672--1682, 2018. Also presented at <i>TADGM Workshop @ICML</i>, 2018. [<a href="paper/2018-COLING.pdf" target="_blank">pdf</a>, <a href="resource/vattn.pdf" target="_blank">slides</a>]</li><br />


<li>Xianggen Liu, <b>Lili Mou</b>, Haotian Cui, Zhengdong Lu, Sen Song. Jumper: Learning when to make classification decision in reading. In <i>Proceedings of the 27th International Joint Conference on Artificial Intelligence (IJCAI)</i>, pages 4237--4243, 2018. [<a href="paper/2018-IJCAI.pdf" target="_blank">pdf</a>, <a href="resource/liuxg.pdf" target="_blank">slides</a> (courtesy of XL)]</li><br />


<li>Zaixiang Zheng,<SUP>1</SUP> Hao Zhou,<SUP>1</SUP> Shujian Huang, <b>Lili Mou</b>, Xin-Yu Dai, Jiajun Chen, Zhaopeng Tu. Modeling past and future for neural machine translation. <i>Transactions of the Association for Computational Linguistics (TACL)</i>, vol. 6, pp. 145--157, 2018. [<a href="paper/2018-TACL-past_future.pdf" target="_blank">pdf</a>]</li><br />



<li>Nabiha Asghar, Pascal Poupart, Jesse Hoey, Xin Jiang, <b>Lili Mou</b>. Affective neural response generation. In <i>Proceedings of European Conference on Information Retrieval (ECIR)</i>, pages 154--166, 2018. [<a href="paper/2018-ECIR-affective.pdf" target="_blank">pdf</a>]</li><br />



<li>Chongyang Tao, <b>Lili Mou</b>, Dongyan Zhao, Rui Yan. RUBER: An unsupervised method for automatic evaluation of open-domain dialog systems. In <i>Proceedings of the 32nd AAAI Conference on Artificial Intelligence (AAAI)</i>, pages 722--729, 2018. [<a href="paper/2018-AAAI-RUBER.pdf" target="_blank">pdf</a>]
</li><br/>

<li>Lei Sha, <b>Lili Mou</b>, Tianyu Liu, Pascal Poupart, Sujian Li, Baobao Chang, Zhifang Sui. Order-planning neural text generation from structure data. In <i>Proceedings of the 32nd AAAI Conference on Artificial Intelligence (AAAI)</i>, pages 5414--5421, 2018. [<a href="paper/2018-AAAI-order.pdf" target="_blank">pdf</a>, <a href="resource/order.pdf", target="_blank">slides</a> (courtesy of LS)]</li><br />

<li>Zhao Meng, <b>Lili Mou</b>, Zhi Jin. Towards neural speaker modeling in multi-party conversation: The task, dataset, and models. In <i>Proceedings of the 32nd AAAI Conference on Artificial Intelligence (AAAI student poster)</i>, pages 8121--8122, 2018. [<a href="paper/2018-AAAI-speaker.pdf" target="_blank">pdf</a>]</li><br/>

<li>Zhao Meng, <b>Lili Mou</b>, Zhi Jin. Hierarchical RNN with static sentence-level attention for text-based speaker change detection. In <i>Proceedings of the 2017 ACM  Conference on Information and Knowledge Management (CIKM-short)</i>, pages 2203--2206, 2017. [<a href="paper/2017-CIKM-SpeakerChange.pdf" target="_blank">pdf</a>]</li><br/>

<li><b>Lili Mou</b>, Zhengdong Lu, Hang Li, Zhi Jin. Coupling distributed and symbolic execution for natural language queries. In <i>Proceedings of the 34th International Conference on Machine Learning (ICML)</i>, pages 2518--2526, 2017. Also presented in <i>ICLR Workshop</i>, 2017. [<a href="http://proceedings.mlr.press/v70/mou17a/mou17a.pdf" target="_blank">pdf</a>, <a href="resource/coupling.pdf" target="_blank">slide</a>]</li><br/>


<li>Zhiliang Tian, Rui Yan, <b>Lili Mou</b>, Yiping Song, Yansong Feng, Dongyan Zhao. How to make context more useful? An empirical study on context-aware neural conversational models. In <i>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL-short)</i>, volume 2, pages 231--236, 2017. [<a href="paper/2017-ACL-context.pdf" target="_blank">pdf</a>]</li><br/>

<li><b>Lili Mou</b>, Yiping Song, Rui Yan, Ge Li, Lu Zhang, Zhi Jin. Sequence to backward and forward sequences: A content-introducing approach to generative short-text conversation. In <i>Proceedings of the 26th International Conference on Computational Linguistics (COLING)</i>, pages 3349--3358, 2016. [<a href="paper/2016-COLING-seq2BF.pdf" target="_blank">pdf</a>, <a href="resource/seq2BF_slide.pdf" target="_blank">slide</a>]</li><br/>

<li>Yan Xu,<sup>1</sup> Ran Jia,<sup>1</sup> <b>Lili Mou</b>, Ge Li, Yunchuan Chen, Yangyang Lu, Zhi Jin. 
Improved relation classification by deep recurrent neural networks with data augmentation.
In <i>Proceedings of the 26th International Conference on Computational Linguistics (COLING)</i>, pages 1461--1470, 2016. 
[<a href="paper/2016-COLING-relation.pdf" target="_blank">pdf</a>]</li><br/>


<li><b>Lili Mou</b>, Zhao Meng, Rui Yan, Ge Li, Yan Xu, Lu Zhang, Zhi Jin. How transferable are neural networks in NLP applications? In <i>Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP)</i>, pages 478--489, 2016.
[<a href="paper/2016-EMNLP-transfer.pdf" target="_blank">pdf</a>]</li><br/>

<li><b>Lili Mou</b>, Ran Jia, Yan Xu, Ge Li, Lu Zhang, Zhi Jin. Distilling word embeddings: An encoding approach. In <i>Proceedings of the Conference on Information and Knowledge Management (CIKM-short)</i>, pages 1977--1980, 2016. Also presented in <i>RL4NLP Workshop @ACL</i>, 2016. [<a href="paper/2016-CIKM-distilling.pdf" target="_blank">pdf</a>]</li><br/>

<li>Yiping Song, <b>Lili Mou</b>, Rui Yan, Li Yi, Zinan Zhu, Xiaohua Hu. Dialogue session segmentation by embedding-enhanced TextTiling. In <i>Proceedings of the 17th Annual Conference of the International Speech Communication Association  (INTERSPEECH)</i>, pages 2706--2710, 2016. [<a href="paper/2016-INTERSPEECH-session_seg.pdf" target="_blank">pdf</a>]</li><br/>

<li>Zhao Meng, <b>Lili Mou</b>, Ge Li, Zhi Jin. Context-aware tree-cased convolutional neural networks for natural language inference. In <i>Proceedings of the 9th International Conference on Knowledge Science, Engineering and Management</i>, pages 515--526, 2016.</li><br />
 
<li>Yunchuan Chen, <b>Lili Mou</b>, Yan Xu, Ge Li, Zhi Jin. Compressing neural language models by sparse word representations. In <i>Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</i>, pages 226--235, 2016. [<a href="paper/2016-ACL-compress.pdf" target="_blank">pdf</a>]</li>

<br/><li><b>Lili Mou</b>,<sup>1</sup> Rui Men,<sup>1</sup> Ge Li, Yan Xu, Lu Zhang, Rui Yan, Zhi Jin. 
Natural language inference by tree-based convolution and heuristic matching.
In <i>Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL-short)</i>, volume 2, pages 130--136, 2016. [<a href="paper/2016-ACL-NLI.pdf" target="_blank">pdf</a>]</li>

<br/><li>Xiang Li, <b>Lili Mou</b>, Rui Yan, Ming Zhang. 
StalemateBreaker: A proactive content-introducing approach to automatic human-computer conversation.
 In <i>Proceedings of the Twenty-Fifth International Conference on Artificial Intelligence (IJCAI)</i>, pages 2845--2851, 2016. [<a href="paper/2016-IJCAI-stalematebreaker.pdf" target="_blank">pdf</a>,
<font color="#ff0000">Reported by <a target="_blank" href="http://www.dailymail.co.uk/sciencetech/article-3548387/Shut-Siri-Researchers-reveal-proactive-AI-mean-end-awkward-silence.html">UK Daily Mail</a>,
<a target="_blank" href="http://www.ccf.org.cn/sites/ccf/nry.jsp?contentId=2924622493828">China Computer Federation (CCF)</a>,
<a target="_blank" href="http://news.pku.edu.cn/xxfz/2016-04/24/content_293529.htm">Peking University</a>,
and several other media</font>]
</li>


<br/><li><b>Lili Mou</b>, Ge Li, Lu Zhang, Tao Wang, Zhi Jin. 
Convolutional neural networks over tree structures for programming language processing.
In <i>Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence (AAAI)</i>, pages 1287--1293, 2016.
[<a href="paper/2016-AAAI-DL4program.pdf" target="_blank">pdf</a>]</li>

<br/><li><b>Lili Mou</b>, Rui Yan, Ge Li, Lu Zhang, Zhi Jin. 
Backward and forward language modeling for constrained sentence generation.
<i>arXiv preprint arXiv:1512.06612</i>, 2015. 
[<a href="https://arXiv.org/pdf/1512.06612.pdf" target="_blank">pdf</a>]</li>

<br/><li><b>Lili Mou</b>, Rui Men, Ge Li, Lu Zhang, Zhi Jin. 
On end-to-end program generation from user intention by deep neural networks. <i>arXiv preprint arXiv:1510.07211</i>, 2015. [<a href="https://arxiv.org/pdf/1510.07211.pdf" target="_blank">pdf</a>, Note: This is a visionary paper.]</li>

<br/><li><b>Lili Mou</b>,<sup>1</sup> Hao Peng,<sup>1</sup> Ge Li, Yan Xu, Lu Zhang, Zhi Jin. 
Discriminative neural sentence modeling by tree-based convolution. In <i>Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)</i>, pages 2315--2325, 2015. [<a href="paper/2015-EMNLP-TBCNN.pdf" target="_blank">pdf</a>,
<a href="resource/tbcnn_slide.pdf" target="_blank">slide</a>]</li>

<br/><li>Hao Peng,<sup>1</sup> <b>Lili Mou</b>,<sup>1</sup> Ge Li, Yunchuan Chen, Yangyang Lu, Zhi Jin. 
A comparative study on regularization strategies for embedding-based neural networks. In <i>Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP-short)</i>, pages 2106--2111, 2015. [<a href="paper/2015-EMNLP-regularization.pdf" target="_blank">pdf</a>]</li>

<br/><li>Yan Xu, <b>Lili Mou</b>, Ge Li, Yunchuan Chen, Hao Peng, Zhi Jin. Classifying relations via long short term memory networks along shortest dependency paths. In <i>Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)</i>, pages 1785--1794, 2015. [<a href="paper/2015-EMNLP-relation.pdf" target="_blank">pdf</a>]</li>

<br/><li>Hao Peng,<sup>1</sup> <b>Lili Mou</b>,<sup>1</sup> Ge Li, Yuxuan Liu, Lu Zhang, Zhi Jin.
Building program vector representations for deep learning.
In <i>Proceedings of the 8th International Conference on Knowledge Science, Engineering and Management</i>, pages 547--553, 2015. 
[extended version: <a href="https://arxiv.org/pdf/1409.3358.pdf" target="_blank">pdf</a>, <a href="resource/PLP.pdf" target="_blank">slide</a>]</li>

<br/><li>Yan Xu, Ge Li, <b>Lili Mou</b>, Yangyang Lu. Learning non-taxomomic relations on demand for ontology extension. <i>International Journal of Software Engineering and Knowledge Engineering</i>, vol. 24, no. 8, pages 1159--1175, 2014.</li>

<br/><li><b>Lili Mou</b>, Ge Li, Zhi Jin, Lu Zhang. 
Verification based on hyponymy hierarchical characteristics 
for Web-based hyponymy discovery.
In <i>Proceedings of the 7th International Conference on Knowledge Science, Engineering and Management</i>, pages 81--92, 2014.</li>

<br/><li>Yiyang Hao, Ge Li, <b>Lili Mou</b>, Lu Zhang, Zhi Jin.
MCT: A tool for commenting programs by multimedia comments.
In <i>Proceedings of the 2013 International Conference on Software Engineering (ICSE-demo)</i>, pages 1339--1342, 2013.</li>

<br/><li><b>Lili Mou</b>, Ge Li, Zhi Jin. 
Domain hyponymy hierarchy discovery by iterative Web searching and inferable semantics based concept selecting.
In <i>Proceedings of the 2013 IEEE 37th Annual Computer Software and Applications Conference</i>, pages 387--392, 2013. [<a href="paper/2013-ICSE-demo.pdf" target="_blank">pdf</a>]</li>

<br/><li><b>Lili Mou</b> Ge Li, Zhi Jin, Yangyang Lu, Yiyang Hao. 
"Discovering domain concepts and hyponymy relations by text relevance classifying based 
iterative Web searching." In <i> Proceedings of 19th Asia-Pacific Software Engineering Conference</i>, pages 213--222, 2012.</li>
</ol>
</font>
</td></tr>
</table>
<br/>
<sup>1</sup>=equal contribution.
<br/><br/>

