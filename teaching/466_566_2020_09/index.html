<!DOCTYPE html>
<html>
	<head>
		<style>
			div {
			max-width: 600px;
			min-width: 100px;
			}
		</style>
	</head>
		
		
<body>
<img src="../../Amii_UofA.png" width="200" >
	
<h1>CMPUT 466/566: Machine Learning</h1>
<h3>Fall 2020</h3>
<h3>Instructor: Lili Mou</h3>

<div>

<p width=200px>
<h3>Course Format </h3> The course will be delivered remotely. UofA members (for credit or auditing) enjoy a private Google Meet lecture room, QA sessions with the instructor and TAs, as well as other social events. <br/><br/>

<ul>
<li>Prerequisites will not be waived for crediting.</li>
<li>The course is full at this moment for students taking for credit. To be listed on the waiting list, the student needs to send an email to explain his/her math and programming background (courses taken since college study). If satsifactory, the instructor will ask the student to fill in a Google Form. If selected, the instructor will send an email to the student. Notice that the chance of enrollment is considered as very low. </li>
<li>Official auditing is always welcome. Just send the audit form to the instructor.</li>
<li>Unofficial sitting through the course is also welcome, and you can find the information on this page.</li>
<li>Adding to eClass is possible for UofA members (students and staff). Just send an email to the instructor.</li>
<li>For non-UofA members, you would not be able to access eClass. But lectures are open accessible to anyone who has Internet access.</li>
</ul>
<a href="https://ualberta-ca.zoom.us/j/98065991261" target="_blank">https://ualberta-ca.zoom.us/j/98065991261</a>

<h3>Lecture time:</h3> 12:30 PM -- 1:50 PM, Tuesday and Thursday, 1-Sep-2020 ~ 7-Dec-2020

<h3>Course Description</h3>

Machine learning teaches a machine to learn from previous experience and makes a prediction for (possibly new) data. This course covers standard materials of a “Machine Learning” course, such as linear regression, linear classification, as well as non-linear models. In the process, we will have a systematic discussion on training criteria, inference criteria, bias-variance tradeoff, etc. The goal of the course is to build a solid foundation of machine learning, so there would be intensive math derivations in lectures, assignments, and exams. 

<h3>Syllabus and Open-Access Information</h3>
Please refer to <a href="https://docs.google.com/document/d/1YVtoUxD9OyeMTH8UBmryXC6wI6v5Qm30Pc7vW19CZv4/edit?usp=sharing" target="_blank">this link</a>.

<h3>Lecture Notes</h3>
<ul>
	<li>1. Introduction [<a href="https://drive.google.com/file/d/1iIH9IA4bEJKpTkYm2pfg3hegzBC27APy/view?usp=sharing" target="_blank">pdf</a>, <a href="https://www.youtube.com/watch?v=f4bQRdN2t54&t=1067s" target="_blank">video</a>]</li>
	
	<li>2. Linear Rergression (Formulation)
		[<a href="https://drive.google.com/file/d/1wIZ0ny2CAUMroCPfO9VkNvpJSeTTZ6JZ/view" target="_blank">pdf</a>, <a href="https://drive.google.com/file/d/1llZv42DGOYCudmYnDuXjOmQqGzLzQAQ7/view" target="_blank">video1</a>,
		<a href="https://drive.google.com/file/d/1bTX5n6PFwh7Tcdahe_C4zgefq8h2Bi1C/view" target="_blank">video2</a>]</li>
	
	<li>3. Linear Rergression (Convexity)
		[<a href="https://drive.google.com/file/d/1cUFBwty2fquz5dboycw1JgVY20DRBc3V/view" target="_blank">pdf</a>, <a href="https://www.youtube.com/watch?v=jAhBhan6Ybg&list=PLKlhhkvvU8-bEzt3Cu1xcvdoyNtZWoNok&index=4ew" target="_blank">video1</a>,
		<a href="https://www.youtube.com/watch?v=ZTgugopEW9w&list=PLKlhhkvvU8-bEzt3Cu1xcvdoyNtZWoNok&index=5g" target="_blank">video2</a>,
				<a href="https://www.youtube.com/watch?v=0-De32v4mXo&list=PLKlhhkvvU8-bEzt3Cu1xcvdoyNtZWoNok&index=6" target="_blank">video3</a>]</li>
			
		<li>4. Linear Rergression (Probabilistic View)
		[<a href="https://drive.google.com/file/d/1nVZ3udNl0z5QJzvUnenzAYAT1PKSe1nG/view?usp=sharing" target="_blank">pdf</a>, <a href="https://www.youtube.com/watch?v=BSiR3qLJfPs&list=PLKlhhkvvU8-bEzt3Cu1xcvdoyNtZWoNok&index=7" target="_blank">video1</a>,
		<a href="https://www.youtube.com/watch?v=sode2bYqasE&list=PLKlhhkvvU8-bEzt3Cu1xcvdoyNtZWoNok&index=8" target="_blank">video2</a>]
		
		<li>5. Linear Rergression (Regularization)
			[<a href="https://drive.google.com/file/d/1VbI3koiubqrLpW6tT3gekWSX2p9AvTtF/view" target="_blank">pdf</a>, <a href="https://www.youtube.com/watch?v=npi9h9Hlycs&list=PLKlhhkvvU8-bEzt3Cu1xcvdoyNtZWoNok&index=9" target="_blank">video1</a>,
			<a href="https://www.youtube.com/watch?v=dkhqpeqffRs&list=PLKlhhkvvU8-bEzt3Cu1xcvdoyNtZWoNok&index=10" target="_blank">video2</a>]
		</li>
	
			<li>6. Linear Rergression (Bayesian Learning)
		[<a href="https://drive.google.com/file/d/1VbI3koiubqrLpW6tT3gekWSX2p9AvTtF/view" target="_blank">pdf</a>, <a href="https://www.youtube.com/watch?v=npi9h9Hlycs&list=PLKlhhkvvU8-bEzt3Cu1xcvdoyNtZWoNok&index=9" target="_blank">video1</a>,
		<a href="https://www.youtube.com/watch?v=dkhqpeqffRs&list=PLKlhhkvvU8-bEzt3Cu1xcvdoyNtZWoNok&index=10" target="_blank">video2</a>]
	</li>

</ul>
<br/><br/><br/>
			
</div>